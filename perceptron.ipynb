{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aqui comienza el estudio del perceptron basico. utilizando el libro *Neural Networks from Scratch in Python*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salida de la neurona #1, 2.3\n"
     ]
    }
   ],
   "source": [
    "# Aqui lo que vemos es una neurona con tres entradas, y por ende tiene \n",
    "# tres pesos y un sesgo\n",
    "inputs = [1, 2, 3] #entradas a mi red neuronal\n",
    "weights = [0.2, 0.8, -0.5] #pesos\n",
    "bias = 2 #sesgo\n",
    "\n",
    "output = (inputs[0]*weights[0] + #salida    #salida = entrada*peso+sesgo   (y = xm+b)\n",
    "inputs[1]*weights[1] +           #para este caso como son tres entradas, por eso se hace tres vecss la operacion y al \n",
    "inputs[2]*weights[2] + bias)        #final se suma el sesgo\n",
    "\n",
    "print(f\"salida de la neurona #1, {output}\") #impresion de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aqui agregamos otra entrada y otro peso, y utilizamos la amnera mas comun de sumar y multiplicar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salida de la neurona #2, 4.8\n"
     ]
    }
   ],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "output = (inputs[0]*weights[0] +        #salida    #salida = entrada*peso+sesgo   (y = xm+b\n",
    "inputs[1]*weights[1] +                  #para este caso como son tres entradas, por eso se hace cuatro vecss la operacion y al \n",
    "inputs[2]*weights[2] +                   #final se suma el sesgo\n",
    "inputs[3]*weights[3] + bias)\n",
    "print(f\"salida de la neurona #2, {output}\") #impresion de salida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tres neuronas, una capa\n",
    "##### Esta es haciendolo de la forma mas basica, multiplicando y sumando uno por uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida de las 3 neuronas [4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "weights1 = [0.2, 0.8, -0.5, 1]\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "outputs = [\n",
    "# Neuron 1:\n",
    "inputs[0]*weights1[0] +\n",
    "inputs[1]*weights1[1] +\n",
    "inputs[2]*weights1[2] +\n",
    "inputs[3]*weights1[3] + bias1,\n",
    "# Neuron 2:\n",
    "inputs[0]*weights2[0] +\n",
    "inputs[1]*weights2[1] +\n",
    "inputs[2]*weights2[2] +\n",
    "inputs[3]*weights2[3] + bias2,\n",
    "# Neuron 3:\n",
    "inputs[0]*weights3[0] +\n",
    "inputs[1]*weights3[1] +\n",
    "inputs[2]*weights3[2] +\n",
    "inputs[3]*weights3[3] + bias3]\n",
    "print(f\"Salida de las 3 neuronas {outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a pesar de lo facil que es hacer esto, cuando se habla de cientos de neuronas es mucho mas dificil programar todo, es por ello que a continucion se presenta el proceso anterior, pero utilizando un ciclo for, en el cual solo tendremos que declarar los vectores de entradas, pesos y sesgos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De esta concatenacion se encarga \"zip\",pesos [0.2, 0.8, -0.5, 1], bias 2\n",
      "Aqui termina la vuelta de los for\n",
      "De esta concatenacion se encarga \"zip\",pesos [0.5, -0.91, 0.26, -0.5], bias 3\n",
      "Aqui termina la vuelta de los for\n",
      "De esta concatenacion se encarga \"zip\",pesos [-0.26, -0.27, 0.17, 0.87], bias 0.5\n",
      "Aqui termina la vuelta de los for\n",
      "salidas [4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    "[0.5, -0.91, 0.26, -0.5],\n",
    "[-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2, 3, 0.5]\n",
    "# Output of current layer\n",
    "layer_outputs = []\n",
    "# For each neuron\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    print(f\"De esta concatenacion se encarga \\\"zip\\\",pesos {neuron_weights}, bias {neuron_bias}\")\n",
    "    # Zeroed output of given neuron\n",
    "    neuron_output = 0\n",
    "    # For each input and weight to the neuron\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "        # Multiply this input by associated weight\n",
    "        # and add to the neuron’s output variable\n",
    "        neuron_output += n_input*weight\n",
    "    # Add bias\n",
    "    neuron_output += neuron_bias\n",
    "    # Put neuron’s result to the layer’s output list\n",
    "    layer_outputs.append(neuron_output)\n",
    "    print(\"Aqui termina la vuelta de los for\")\n",
    "print(f\"salidas {layer_outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicacion de lista de listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,5,6,2]\n",
    "#A list of lists:\n",
    "lol = [[1,5,6,2],\n",
    "[3,2,1,3]]\n",
    "#A list of lists of lists!\n",
    "lolol = [[[1,5,6,2], \n",
    "          [3,2,1,3]],\n",
    "          [[5,2,1,2],\n",
    "           [6,4,8,4]],\n",
    "           [[2,8,5,3],\n",
    "            [1,1,9,4]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producto punto\n",
    "#### El producto punto se desarrolla de la siguiente manera,al tener dos vectores multiplicamos los mismos indices de cada arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [2,3,4]\n",
    "\n",
    "dot_product = a[0]*b[0] + a[1]*b[1] + a[2]*b[2]\n",
    "print(dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una sola neurona con NumPy\n",
    "#### Como podremos observar np.dot se encraga de hacer lo que normalmente hacemos para el producto punto y se encarga de realizarlo para todos los valores de las listas, y al final se suma el Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [0.2, 0.8, -0.5, 1.0]\n",
    "bias = 2.0\n",
    "\n",
    "outputs = np.dot(weights, inputs) + bias\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy y tres neuronas\n",
    "#### una capa de neuronas con numpy\n",
    "\n",
    "#### Aqui numpy se encarga de realizar la multiplicacion de cada  entrada por su peso y al final le suma el bias, es lo que hicimos anteriormente con el for, pero ahora con menos lineas de codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    "[0.5, -0.91, 0.26, -0.5],\n",
    "[-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "print(layer_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un conjunto de datos\n",
    "#### An example of a batch of data could look like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape = (8, 4)\n",
    "# type = 2D array, matriz\n",
    "inputs = [[1, 2, 3, 2.5],\n",
    "          [2, 5, -1, 2],\n",
    "          [1, 2, 3, 2.5],\n",
    "          [1, 2, 3, 2.5],\n",
    "          [2, 5, -1, 2],\n",
    "          [1, 2, 3, 2.5],\n",
    "          [2, 5, -1, 2],\n",
    "          [1, 2, 3, 2.5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producto de matrices\n",
    "### Una vez visto el producto punto, vamos a ver lo que el producto de matrices\n",
    "\n",
    "##### El producto matricial es una operación en la que tenemos 2 matrices, y estamos realizando productos escalar de todas las combinaciones de filas de la primera matriz y las columnas de la 2ª matriz, dando como resultado una matriz de esos productos de puntos atómicos\n",
    "\n",
    "##### En matemáticas, podemos tener algo llamado vector columna y vector fila, que explicaremos mejor en breve. Son vectores, pero representados como matrices con una de las dimensiones que tiene un tamaño de 1\n",
    "\n",
    "para poder multiplicar vectores debemos tenerlos como vectores fila y vectores columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposicion de la matriz producto\n",
    "Con NumPy y con 3 valores, lo definiríamos como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.array([[1, 2, 3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta el uso de corchetes dobles aquí. Para transformar una lista en una matriz que contenga una sola fila (realizar una operación equivalente de convertir un vector en un vector fila), podemos ponerlo en una lista y crear una matriz numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "np.array([a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez más, tenga en cuenta que encerramos a entre paréntesis antes de convertir en una matriz en este caso. O podemos convertirlo en una matriz 1D y expandir las dimensiones usando una de las habilidades de NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "np.expand_dims(np.array(a), axis=0)\n",
    "#Donde np.expand_dims() añade una nueva dimensión en el índice del eje. Un vector \n",
    "#columna es una matriz donde el tamaño de la segunda dimensión es igual a 1, en otras\n",
    "#palabras, es una matriz de forma (n, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# con codigo numpy:\n",
    "import numpy as np\n",
    "a = [1, 2, 3]\n",
    "b = [2, 3, 4]\n",
    "a = np.array([a])\n",
    "b = np.array([b]).T\n",
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una capa de neuronas y un lote de datos con NumPy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
